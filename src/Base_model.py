# -*- coding: utf-8 -*-
"""model1(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZQ1EijMoR6TFUCffTRbKuXmcI1G_xU9i
"""

!pip install mne
from google.colab import drive
drive.mount('/content/drive')
import numpy as np
import pandas as pd
import random
import os
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.nn.functional as F
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.fftpack import fft, fftfreq, rfft, rfftfreq
from sklearn.preprocessing import quantile_transform
from sklearn.preprocessing import minmax_scale
from sklearn.preprocessing import normalize
from sklearn.preprocessing import scale
from sklearn.preprocessing import robust_scale
import mne
import matplotlib
from collections import defaultdict
from math import cos, sin, acos, radians, pi
from scipy.interpolate import griddata
from numpy import newaxis
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

print("Starting...")
print()
#GPU check     )
device = torch.device('cpu')#torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("Current device is:", device, ". Please abort and turn on cuda, if not already activated.")
print()
print("Importing data from file...")

#Random Seed
seed = 123
random.seed = seed

#File Import

filenames_list = os.listdir(r'/content/drive/MyDrive/Conrad/eegdata/eegdata/SMNI_CMI_TRAIN/Train/') ## list of file names in the directory


EEG_data = pd.DataFrame({}) ## create an empty df that will hold data from each file
EEG_data_control = pd.DataFrame({})
number = 0

for file_name in filenames_list:
    temp_df = pd.read_csv(r'/content/drive/MyDrive/Conrad/eegdata/eegdata/SMNI_CMI_TRAIN/Train/' + file_name, engine = 'c') ## read from the file to df
    number += 1

    if 'a' in temp_df['subject identifier'].values:

        EEG_data = EEG_data.append(temp_df) ## add the file data to the main df


    if 'c' in temp_df['subject identifier'].values:

        EEG_data_control = EEG_data_control.append(temp_df) ## add the file data to the main df



EEG_data = EEG_data.drop(['Unnamed: 0'], axis=1) ## remove the unused column
EEG_data.loc[EEG_data['matching condition'] == 'S2 nomatch,', 'matching condition'] =  'S2 nomatch' ## remove comma sign from stimulus name

## replace some 'sensor position' values for uniform electron name
EEG_data.loc[EEG_data['sensor position'] == 'AF1', 'sensor position'] = 'AF3'
EEG_data.loc[EEG_data['sensor position'] == 'AF2', 'sensor position'] = 'AF4'
EEG_data.loc[EEG_data['sensor position'] == 'PO1', 'sensor position'] = 'PO3'
EEG_data.loc[EEG_data['sensor position'] == 'PO2', 'sensor position'] = 'PO4'

EEG_data.loc[EEG_data['sensor position'] == 'FP1', 'sensor position'] = 'Fp1'
EEG_data.loc[EEG_data['sensor position'] == 'FP2', 'sensor position'] = 'Fp2'
EEG_data.loc[EEG_data['sensor position'] == 'CPZ', 'sensor position'] = 'CPz'
EEG_data.loc[EEG_data['sensor position'] == 'FZ', 'sensor position'] = 'Fz'

EEG_data.loc[EEG_data['sensor position'] == 'CZ', 'sensor position'] = 'Cz' ## exclusion of this position because it has a systematically extrem value

EEG_data.loc[EEG_data['sensor position'] == 'PZ', 'sensor position'] = 'Pz'
EEG_data.loc[EEG_data['sensor position'] == 'FPZ', 'sensor position'] = 'Fpz'
EEG_data.loc[EEG_data['sensor position'] == 'AFZ', 'sensor position'] = 'AFz'
EEG_data.loc[EEG_data['sensor position'] == 'FCZ', 'sensor position'] = 'FCz'

EEG_data.loc[EEG_data['sensor position'] == 'POZ', 'sensor position'] = 'POz'
EEG_data.loc[EEG_data['sensor position'] == 'OZ', 'sensor position'] = 'Oz'

###same for control

EEG_data_control = EEG_data_control.drop(['Unnamed: 0'], axis=1) ## remove the unused column
EEG_data_control.loc[EEG_data_control['matching condition'] == 'S2 nomatch,', 'matching condition'] =  'S2 nomatch' ## remove comma sign from stimulus name
## replace some 'sensor position' values
EEG_data_control.loc[EEG_data_control['sensor position'] == 'AF1', 'sensor position'] = 'AF3'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'AF2', 'sensor position'] = 'AF4'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'PO1', 'sensor position'] = 'PO3'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'PO2', 'sensor position'] = 'PO4'

EEG_data_control.loc[EEG_data_control['sensor position'] == 'FP1', 'sensor position'] = 'Fp1'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'FP2', 'sensor position'] = 'Fp2'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'CPZ', 'sensor position'] = 'CPz'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'FZ', 'sensor position'] = 'Fz'

EEG_data_control.loc[EEG_data_control['sensor position'] == 'CZ', 'sensor position'] = 'Cz' ## exclusion of this position because it has a systematically extrem value

EEG_data_control.loc[EEG_data_control['sensor position'] == 'PZ', 'sensor position'] = 'Pz'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'FPZ', 'sensor position'] = 'Fpz'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'AFZ', 'sensor position'] = 'AFz'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'FCZ', 'sensor position'] = 'FCz'

EEG_data_control.loc[EEG_data_control['sensor position'] == 'POZ', 'sensor position'] = 'POz'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'OZ', 'sensor position'] = 'Oz'

print()
print("Preprocessing data...")
print()

# build matrix 64 by 256 FOR each trial number

Alc_base = EEG_data['trial number'].unique()
Con_base = EEG_data_control['trial number'].unique()

##Train Test split 80%

lstp_Alc1 = int(round((len(Alc_base)/100)*80.0))
# lstp_Alc2 = int(round((len(Alc_base)/100)*66.66))

# Alc_train_extractor = Alc_base[:lstp_Alc1]
Alc_train_classifier =Alc_base[:lstp_Alc1]
Alc_test = Alc_base[lstp_Alc1:]


lstp_Con1 = int(round((len(Con_base)/100)*80.0))
# lstp_Con2 = int(round((len(Con_base)/100)*66.66))

# Con_train_extractor = Con_base[:lstp_Con1]
Con_train_classifier = Con_base[:lstp_Con1]
Con_test = Con_base[lstp_Con1:]

def trialfunction(input_data):

    trials_dic = {}

    dbc = 0

    if Alc_train_classifier.shape == Con_train_classifier.shape:

        print('Same shape error:')
        print(X_train.shape)
        print(y_train.shape)
        raise SystemExit

    if (input_data.shape == Alc_train_classifier.shape) or (input_data.shape == Alc_test.shape):
        dbc = EEG_data


    if (input_data.shape == Con_train_classifier.shape) or (input_data.shape == Con_test.shape):
        dbc = EEG_data_control


    for pos in input_data:

        Trial = dbc.loc[dbc['trial number'] == pos]

        columns =['channel','time', 'sensor value']

        Trial = Trial.pivot_table(index='channel', columns='time', values = 'sensor value')

        trials_dic[pos] = Trial



    RGB_dic = {}



    for key in trials_dic:
        data = trials_dic.get(key)

        # Get real amplitudes of FFT (only in postive frequencies)

        fft_raw = fft(data)

        fft_vals = np.absolute(fft_raw)

        fft_vals = normalize(fft_vals, axis=1)

        # Get frequencies for amplitudes in Hz

        fs = 256    # Sampling rate

        fft_freq = fftfreq(fs, 1.0/fs)

        # Define EEG bands
        eeg_bands = {'Theta': (4, 7),
                 'Alpha': (8, 12),
                 'Beta': (13, 30),
                 }

        # Take the  sum of squared absolute values/amplitudes for each EEG band

        eeg_band_fft = defaultdict(list)

        for band in eeg_bands:


            freq_ix = np.where((fft_freq >= eeg_bands[band][0]) &
                               (fft_freq <= eeg_bands[band][1]))[0]



            for channel in fft_vals:

                filterdch = channel[freq_ix]

                sqdvals = np.square(filterdch)

                sumvals = np.sum(sqdvals, axis=0)

                eeg_band_fft[band].append(sumvals)




        extracted_df =  pd.DataFrame(eeg_band_fft)




        neeg = EEG_data.drop(columns=['matching condition','name','trial number', 'subject identifier','time', 'sample num', 'sensor value'])

        neeg = neeg.drop_duplicates()


        #get names of source elctrodes:

        extracted_df = extracted_df.reset_index(drop=True)
        neeg = neeg.reset_index(drop=True)



        e_names =  neeg
        e_names = e_names.rename(columns = {'sensor position' : 0})



        extracted_df = extracted_df.join(neeg)


        #get coordinates in 3d from robertoostenveld.nl/electrodes/plotting_1005.txt

        coords = pd.read_csv(r'/content/drive/MyDrive/Conrad/eegdata/eegdata/plotting_1005.txt', sep='\t',  header = None)

        coords = coords.drop(coords.columns[4], axis=1)

        #print(coords)
        testerd = pd.merge(e_names, coords, on=0,  how='inner')


        testerd.set_index('channel', inplace=True)

        testerd.columns = ['pos','x', 'y', 'z']


        extracted_df = extracted_df.rename(columns={'sensor position': "pos"})

        #filter values and coordinates
        extracted_df = pd.merge(extracted_df, testerd, on="pos", how='inner')
        extracted_df = extracted_df.drop(['x','y','z'], axis=1)
        extracted_df.set_index('channel', inplace=True)

        extracted_df = extracted_df.drop(columns=['pos'])
        extracted_df.index.names = ['pos']


        #adapted from https://www.samuelbosch.com/2014/02/azimuthal-equidistant-projection.html

        class Point(object):
            def __init__(self,x, y, z):
                self.x = x
                self.y = y
                self.z = z

        class AzimuthalEquidistantProjection(object):
            """
                http://mathworld.wolfram.com/AzimuthalEquidistantProjection.html
                http://mathworld.wolfram.com/SphericalCoordinates.html
            """
            def __init__(self):

                self.t1 = pi / 2 ## polar latitude center of projection , https://en.wikipedia.org/wiki/Azimuthal_equidistant_projection
                self.l0 = 0 ## arbitrary longitude center of projection
                self.cost1 = cos(self.t1)
                self.sint1 = sin(self.t1)

            def project(self, point):

                #ADDAPTED FOR 3D CARTESIAN TO SPHERICAL

                hxy = np.hypot(point.x, point.y)

                t = np.arctan2(point.z, hxy)
                l = np.arctan2(point.y, point.x)

                ###

                costcosll0 = cos(t) * cos(l-self.l0)
                sint = sin(t)

                c = acos ((self.sint1) * (sint) + (self.cost1) * costcosll0)
                k = c / sin(c)

                x = k * cos(t) * sin(l-self.l0)
                y = k * (self.cost1 * sint - self.sint1 * costcosll0)
                return x, y



        #Projection df

        projected_df =  pd.DataFrame()

        for index, row in testerd.iterrows():

            x = row['x']
            y = row['y']
            z = row['z']


            p = AzimuthalEquidistantProjection()
            r = p.project(Point(x,y,z))

            r = pd.Series(r)

            projected_df = projected_df.append(r,ignore_index=True)


        projected_df =  projected_df.rename(columns={0: 'X',1: 'Y'})


        ###map coodinate with valuies

        new_df = projected_df.join(extracted_df)
        new_df = new_df.drop([31]) # drop row because i contains no values
        #print(new_df)

        Theta_df = new_df.drop(['Alpha','Beta','X','Y'], axis=1)
        Alpha_df = new_df.drop(['Theta','Beta','X','Y'], axis=1)
        Beta_df = new_df.drop(['Theta','Alpha','X','Y'], axis=1)


        #map onto mesh

        xpoints = np.array(new_df[['X']].squeeze())
        ypoints = np.array(new_df[['Y']].squeeze())

        Thetavalues = np.array(Theta_df).squeeze()
        Alphavalues = np.array(Alpha_df).squeeze()
        Betavalues = np.array(Beta_df).squeeze()


        xx,yy = np.mgrid[-1.5:1.5:32j, -1.5:1.5:32j]

        Thetavalues = minmax_scale(Thetavalues,feature_range=(0.0, 1.0), axis=0)
        Alphavalues = minmax_scale(Alphavalues,feature_range=(0.0, 1.0), axis=0)
        Betavalues = minmax_scale(Betavalues,feature_range=(0.0, 1.0), axis=0)


        Thetagrid = griddata((xpoints, ypoints), Thetavalues, (xx, yy),method='cubic', fill_value = 0.0)
        Alphagrid = griddata((xpoints, ypoints), Alphavalues, (xx, yy),method='cubic', fill_value = 0.0)
        Betagrid = griddata((xpoints, ypoints), Betavalues, (xx, yy),method='cubic', fill_value = 0.0)


        ##RGB construction

        RGB = np.empty((32, 32, 3))

        RGB[:,:,0] = Thetagrid
        RGB[:,:,1] = Alphagrid
        RGB[:,:,2] = Betagrid



        RGB_dic[key] = RGB



    ##creating new dict with new keys

    lendict = len(RGB_dic)
    #print('lendict: ',lendict)

    lenlist=np.arange(0,lendict)

    #print(lenlist)

    final_dict = dict(zip(lenlist, list(RGB_dic.values())))


    return final_dict

print("Constructing Dataset...")

###Dataset construction

class EEGRGBDataset(Dataset):

    def __init__(self, file, transform=None):

        self.file = file
        self.transform = transform

    def __len__(self):
        return len(self.file)


    def __getitem__(self, idx):

        sample = self.file[idx]

        if self.transform:
            sample = self.transform(sample)

        return sample

####Tensor transform


class ToTensor(object):
    def __call__(self, sample):

        sample = sample.transpose((2, 0, 1))
        sample = torch.tensor(sample, dtype = torch.float, device = device)

        return sample

### Function Call

# final_dict1 = trialfunction(Alc_train_extractor)
# final_dict2 = trialfunction(Con_train_extractor)
final_dict3 = trialfunction(Alc_train_classifier)
final_dict4 = trialfunction(Con_train_classifier)
final_dict5 = trialfunction(Alc_test)
final_dict6 = trialfunction(Con_test)

##

# eeg_dataset1 = EEGRGBDataset(final_dict1)
# eeg_dataset2 = EEGRGBDataset(final_dict2)

eeg_dataset3 = EEGRGBDataset(final_dict3)
eeg_dataset4 = EEGRGBDataset(final_dict4)

eeg_dataset5 = EEGRGBDataset(final_dict5)
eeg_dataset6 = EEGRGBDataset(final_dict6)

##

# transformed_dataset1 = EEGRGBDataset(eeg_dataset1, transform=transforms.Compose([ToTensor()]))
# transformed_dataset2 = EEGRGBDataset(eeg_dataset2, transform=transforms.Compose([ToTensor()]))

transformed_dataset3 = EEGRGBDataset(eeg_dataset3, transform=transforms.Compose([ToTensor()]))
transformed_dataset4 = EEGRGBDataset(eeg_dataset4, transform=transforms.Compose([ToTensor()]))

transformed_dataset5 = EEGRGBDataset(eeg_dataset5, transform=transforms.Compose([ToTensor()]))
transformed_dataset6 = EEGRGBDataset(eeg_dataset6, transform=transforms.Compose([ToTensor()]))

###Batch construction

bsize = 10
workers = 0


# loader1_Alc_train_extractor = DataLoader(transformed_dataset1, batch_size=bsize, num_workers=workers)
# loader2_Con_train_extractor = DataLoader(transformed_dataset2, batch_size=bsize, num_workers=workers)

loader3_Alc_train_classifier = DataLoader(transformed_dataset3, batch_size=bsize, num_workers=workers)
loader4_Con_train_classifier = DataLoader(transformed_dataset4, batch_size=bsize, num_workers=workers)

loader5_Alc_test = DataLoader(transformed_dataset5, batch_size=bsize, num_workers=workers)
loader6_Con_test = DataLoader(transformed_dataset6, batch_size=bsize, num_workers=workers)



distance = nn.MSELoss()

# Tensor construction
# for pytorch, the right format for image is [batch, channels, height, width]

#Training procedure

num_epochs = 1000

def feature_extractor(loader):

    with torch.no_grad():

        imagebatch = 0
        n = 0

        for batch in loader:
            n += 1

            inputs = batch

            if n == 1:
                imagebatch = batch

            else:
                imagebatch = torch.cat([imagebatch, batch], dim=0, out=None)

        return imagebatch

### images for input

images_Alc_train_classifier = feature_extractor(loader3_Alc_train_classifier)
images_Con_train_classifier = feature_extractor(loader4_Con_train_classifier)

images_Alc_test_classifier = feature_extractor(loader5_Alc_test)
images_Con_test_classifier = feature_extractor(loader6_Con_test)


import numpy as np


##Labels

y_Alc_train_classifier = np.ones([images_Alc_train_classifier.shape[0]])
y_Con_train_classifier = np.zeros([images_Con_train_classifier.shape[0]])

y_Alc_test_classifier = np.ones([images_Alc_test_classifier.shape[0]])
y_Con_test_classifier= np.zeros([images_Con_test_classifier.shape[0]])

y_train_classifier = np.concatenate([y_Alc_train_classifier, y_Con_train_classifier], axis=0)
y_test_classifier = np.concatenate([y_Alc_test_classifier, y_Con_test_classifier], axis=0)

images_train_classifier = torch.cat([images_Alc_train_classifier, images_Con_train_classifier], dim=0)
images_test_classifier = torch.cat([images_Alc_test_classifier, images_Con_test_classifier], dim=0)




###into multiarray
images_train_classifier = images_train_classifier.cpu().numpy()

images_test_classifier = images_test_classifier.cpu().numpy()

###

from sklearn.utils import shuffle

S_images_train_classifier, S_y_train_classifier = shuffle(images_train_classifier, y_train_classifier, random_state=0)
S_images_test_classifier, S_y_test_classifier = shuffle(images_test_classifier, y_test_classifier, random_state=0)


###back to tensor
S_y_train_classifier = torch.tensor(S_y_train_classifier, dtype=torch.float, device = device)
S_y_test_classifier = torch.tensor(S_y_test_classifier, dtype=torch.float, device = device)

S_images_train_classifier = torch.tensor(S_images_train_classifier, dtype=torch.float, device = device)
S_images_test_classifier = torch.tensor(S_images_test_classifier, dtype=torch.float, device = device)




###flatten
Flat_S_images_train_classifier = torch.flatten(S_images_train_classifier,start_dim=1, end_dim=-1)
Flat_S_images_test_classifier = torch.flatten(S_images_test_classifier,start_dim=1, end_dim=-1)

class FeedforwardNeuralNetModel(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(FeedforwardNeuralNetModel, self).__init__()

        self.input_size = input_size
        self.hidden_size  = hidden_size
        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)
        self.relu = torch.nn.ReLU()
        self.fc2 = torch.nn.Linear(self.hidden_size, 1)
        self.sigmoid = torch.nn.Sigmoid()

    def forward(self, x):
        hidden = self.fc1(x)
        relu = self.relu(hidden)
        output = self.fc2(relu)
        output = self.sigmoid(output)
        return output

####
print()
print("Training classification models for imagesfor 100 epochs..")
print()
#Train FeedforwardNeuralNetModel

model = FeedforwardNeuralNetModel(3072,10)

distance =  nn.BCELoss()

FFoptimizer2 = torch.optim.SGD(model.parameters(), lr = 0.01)

#Training procedure

FFnum_epochs = 100

def FFtrainer(loaderx,labels, model, optimizer):

    for epoch in range(FFnum_epochs):

        optimizer.zero_grad()
        # Forward pass
        y_pred = model(loaderx)
        # Compute Loss
        loss = distance(y_pred.squeeze(), labels)

        # Backward pass
        loss.backward()
        optimizer.step()


        print('Epoch {}: train loss: {}'.format(epoch, loss.item()))

        # Print loss per epoch
        # if epoch == 0 or epoch == FFnum_epochs-1:
        #     print('Epoch {}: train loss: {}'.format(epoch, loss.item()))


### Determine test loss before training on test set


model.eval()
y_pred2 = model(Flat_S_images_test_classifier)
before_train = distance(y_pred2.squeeze(), S_y_test_classifier)
print('Test loss before training on images' , before_train.item())


#Training Call

model.train()
Model_images_train_classifier = FFtrainer(Flat_S_images_train_classifier,S_y_train_classifier,model,FFoptimizer2)


# Evaluation

model.eval()
y_pred = model(Flat_S_images_test_classifier)
after_train = distance(y_pred.squeeze(), S_y_test_classifier)
print('Test loss after Training on images' , after_train.item())

#Accuracy

output_pred = (y_pred>0.5).float()
correct = (output_pred.squeeze() == S_y_test_classifier).cpu().numpy().sum()
incorrect = (output_pred.squeeze() != S_y_test_classifier).cpu().numpy().sum()
total = correct + incorrect
accuracy = 100 * correct / total

print()
print("Summary of classifier accuracy:")
print()
print('Image accuracy:',accuracy,'%')
print()
print('In ',total,' test cases' )
print()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# 计算混淆矩阵
true_labels = S_y_test_classifier.cpu().numpy()
predicted_labels = output_pred.cpu().numpy()
cm = confusion_matrix(true_labels, predicted_labels)

# 绘制混淆矩阵
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()



