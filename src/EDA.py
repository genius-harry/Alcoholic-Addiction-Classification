# -*- coding: utf-8 -*-
"""model1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GoMYAoLrukEFrRFy-kMiHLVhsgZvjOBg
"""

!pip install mne

import numpy as np
import pandas as pd
import random
import os
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.nn.functional as F
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.fftpack import fft, fftfreq, rfft, rfftfreq
from sklearn.preprocessing import quantile_transform
from sklearn.preprocessing import minmax_scale
from sklearn.preprocessing import normalize
from sklearn.preprocessing import scale
from sklearn.preprocessing import robust_scale
import mne
import matplotlib
from collections import defaultdict
from math import cos, sin, acos, radians, pi
from scipy.interpolate import griddata
from numpy import newaxis
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

from google.colab import drive
drive.mount('/content/drive')

print("Starting...")
print()
#GPU check     )
device = torch.device('cpu')#torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("Current device is:", device, ". Please abort and turn on cuda, if not already activated.")
print()
print("Importing data from file...")

#Random Seed
seed = 123
random.seed = seed

#File Import

filenames_list = os.listdir(r'/content/drive/MyDrive/Conrad/eegdata/eegdata/SMNI_CMI_TRAIN/Train/') ## list of file names in the directory


EEG_data = pd.DataFrame({}) ## create an empty df that will hold data from each file
EEG_data_control = pd.DataFrame({})
number = 0

for file_name in filenames_list:
    temp_df = pd.read_csv(r'/content/drive/MyDrive/Conrad/eegdata/eegdata/SMNI_CMI_TRAIN/Train/' + file_name, engine = 'c') ## read from the file to df
    number += 1

    if 'a' in temp_df['subject identifier'].values:

        EEG_data = EEG_data.append(temp_df) ## add the file data to the main df


    if 'c' in temp_df['subject identifier'].values:

        EEG_data_control = EEG_data_control.append(temp_df) ## add the file data to the main df



EEG_data = EEG_data.drop(['Unnamed: 0'], axis=1) ## remove the unused column
EEG_data.loc[EEG_data['matching condition'] == 'S2 nomatch,', 'matching condition'] =  'S2 nomatch' ## remove comma sign from stimulus name

## replace some 'sensor position' values for uniform electron name
EEG_data.loc[EEG_data['sensor position'] == 'AF1', 'sensor position'] = 'AF3'
EEG_data.loc[EEG_data['sensor position'] == 'AF2', 'sensor position'] = 'AF4'
EEG_data.loc[EEG_data['sensor position'] == 'PO1', 'sensor position'] = 'PO3'
EEG_data.loc[EEG_data['sensor position'] == 'PO2', 'sensor position'] = 'PO4'

EEG_data.loc[EEG_data['sensor position'] == 'FP1', 'sensor position'] = 'Fp1'
EEG_data.loc[EEG_data['sensor position'] == 'FP2', 'sensor position'] = 'Fp2'
EEG_data.loc[EEG_data['sensor position'] == 'CPZ', 'sensor position'] = 'CPz'
EEG_data.loc[EEG_data['sensor position'] == 'FZ', 'sensor position'] = 'Fz'

EEG_data.loc[EEG_data['sensor position'] == 'CZ', 'sensor position'] = 'Cz' ## exclusion of this position because it has a systematically extrem value

EEG_data.loc[EEG_data['sensor position'] == 'PZ', 'sensor position'] = 'Pz'
EEG_data.loc[EEG_data['sensor position'] == 'FPZ', 'sensor position'] = 'Fpz'
EEG_data.loc[EEG_data['sensor position'] == 'AFZ', 'sensor position'] = 'AFz'
EEG_data.loc[EEG_data['sensor position'] == 'FCZ', 'sensor position'] = 'FCz'

EEG_data.loc[EEG_data['sensor position'] == 'POZ', 'sensor position'] = 'POz'
EEG_data.loc[EEG_data['sensor position'] == 'OZ', 'sensor position'] = 'Oz'

###same for control

EEG_data_control = EEG_data_control.drop(['Unnamed: 0'], axis=1) ## remove the unused column
EEG_data_control.loc[EEG_data_control['matching condition'] == 'S2 nomatch,', 'matching condition'] =  'S2 nomatch' ## remove comma sign from stimulus name
## replace some 'sensor position' values
EEG_data_control.loc[EEG_data_control['sensor position'] == 'AF1', 'sensor position'] = 'AF3'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'AF2', 'sensor position'] = 'AF4'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'PO1', 'sensor position'] = 'PO3'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'PO2', 'sensor position'] = 'PO4'

EEG_data_control.loc[EEG_data_control['sensor position'] == 'FP1', 'sensor position'] = 'Fp1'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'FP2', 'sensor position'] = 'Fp2'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'CPZ', 'sensor position'] = 'CPz'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'FZ', 'sensor position'] = 'Fz'

EEG_data_control.loc[EEG_data_control['sensor position'] == 'CZ', 'sensor position'] = 'Cz' ## exclusion of this position because it has a systematically extrem value

EEG_data_control.loc[EEG_data_control['sensor position'] == 'PZ', 'sensor position'] = 'Pz'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'FPZ', 'sensor position'] = 'Fpz'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'AFZ', 'sensor position'] = 'AFz'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'FCZ', 'sensor position'] = 'FCz'

EEG_data_control.loc[EEG_data_control['sensor position'] == 'POZ', 'sensor position'] = 'POz'
EEG_data_control.loc[EEG_data_control['sensor position'] == 'OZ', 'sensor position'] = 'Oz'

print()
print("Preprocessing data...")
print()

# build matrix 64 by 256 FOR each trial number

Alc_base = EEG_data['trial number'].unique()
Con_base = EEG_data_control['trial number'].unique()

##Train Test split 80%

lstp_Alc1 = int(round((len(Alc_base)/100)*80.0))
# lstp_Alc2 = int(round((len(Alc_base)/100)*66.66))

# Alc_train_extractor = Alc_base[:lstp_Alc1]
Alc_train_classifier =Alc_base[:lstp_Alc1]
Alc_test = Alc_base[lstp_Alc1:]


lstp_Con1 = int(round((len(Con_base)/100)*80.0))
# lstp_Con2 = int(round((len(Con_base)/100)*66.66))

# Con_train_extractor = Con_base[:lstp_Con1]
Con_train_classifier = Con_base[:lstp_Con1]
Con_test = Con_base[lstp_Con1:]

def trialfunction(input_data):

    trials_dic = {}

    dbc = 0

    if Alc_train_classifier.shape == Con_train_classifier.shape:

        print('Same shape error:')
        print(X_train.shape)
        print(y_train.shape)
        raise SystemExit

    if (input_data.shape == Alc_train_classifier.shape) or (input_data.shape == Alc_test.shape):
        dbc = EEG_data


    if (input_data.shape == Con_train_classifier.shape) or (input_data.shape == Con_test.shape):
        dbc = EEG_data_control


    for pos in input_data:

        Trial = dbc.loc[dbc['trial number'] == pos]

        columns =['channel','time', 'sensor value']

        Trial = Trial.pivot_table(index='channel', columns='time', values = 'sensor value')

        trials_dic[pos] = Trial



    RGB_dic = {}



    for key in trials_dic:
        data = trials_dic.get(key)

        # Get real amplitudes of FFT (only in postive frequencies)

        fft_raw = fft(data)

        fft_vals = np.absolute(fft_raw)

        fft_vals = normalize(fft_vals, axis=1)

        # Get frequencies for amplitudes in Hz

        fs = 256    # Sampling rate

        fft_freq = fftfreq(fs, 1.0/fs)

        # Define EEG bands
        eeg_bands = {'Theta': (4, 7),
                 'Alpha': (8, 12),
                 'Beta': (13, 30),
                 }

        # Take the  sum of squared absolute values/amplitudes for each EEG band

        eeg_band_fft = defaultdict(list)

        for band in eeg_bands:


            freq_ix = np.where((fft_freq >= eeg_bands[band][0]) &
                               (fft_freq <= eeg_bands[band][1]))[0]



            for channel in fft_vals:

                filterdch = channel[freq_ix]

                sqdvals = np.square(filterdch)

                sumvals = np.sum(sqdvals, axis=0)

                eeg_band_fft[band].append(sumvals)




        extracted_df =  pd.DataFrame(eeg_band_fft)




        neeg = EEG_data.drop(columns=['matching condition','name','trial number', 'subject identifier','time', 'sample num', 'sensor value'])

        neeg = neeg.drop_duplicates()


        #get names of source elctrodes:

        extracted_df = extracted_df.reset_index(drop=True)
        neeg = neeg.reset_index(drop=True)



        e_names =  neeg
        e_names = e_names.rename(columns = {'sensor position' : 0})



        extracted_df = extracted_df.join(neeg)


        #get coordinates in 3d from robertoostenveld.nl/electrodes/plotting_1005.txt

        coords = pd.read_csv(r'/content/drive/MyDrive/Conrad/eegdata/eegdata/plotting_1005.txt', sep='\t',  header = None)

        coords = coords.drop(coords.columns[4], axis=1)

        #print(coords)
        testerd = pd.merge(e_names, coords, on=0,  how='inner')


        testerd.set_index('channel', inplace=True)

        testerd.columns = ['pos','x', 'y', 'z']


        extracted_df = extracted_df.rename(columns={'sensor position': "pos"})

        #filter values and coordinates
        extracted_df = pd.merge(extracted_df, testerd, on="pos", how='inner')
        extracted_df = extracted_df.drop(['x','y','z'], axis=1)
        extracted_df.set_index('channel', inplace=True)

        extracted_df = extracted_df.drop(columns=['pos'])
        extracted_df.index.names = ['pos']


        #adapted from https://www.samuelbosch.com/2014/02/azimuthal-equidistant-projection.html

        class Point(object):
            def __init__(self,x, y, z):
                self.x = x
                self.y = y
                self.z = z

        class AzimuthalEquidistantProjection(object):
            """
                http://mathworld.wolfram.com/AzimuthalEquidistantProjection.html
                http://mathworld.wolfram.com/SphericalCoordinates.html
            """
            def __init__(self):

                self.t1 = pi / 2 ## polar latitude center of projection , https://en.wikipedia.org/wiki/Azimuthal_equidistant_projection
                self.l0 = 0 ## arbitrary longitude center of projection
                self.cost1 = cos(self.t1)
                self.sint1 = sin(self.t1)

            def project(self, point):

                #ADDAPTED FOR 3D CARTESIAN TO SPHERICAL

                hxy = np.hypot(point.x, point.y)

                t = np.arctan2(point.z, hxy)
                l = np.arctan2(point.y, point.x)

                ###

                costcosll0 = cos(t) * cos(l-self.l0)
                sint = sin(t)

                c = acos ((self.sint1) * (sint) + (self.cost1) * costcosll0)
                k = c / sin(c)

                x = k * cos(t) * sin(l-self.l0)
                y = k * (self.cost1 * sint - self.sint1 * costcosll0)
                return x, y



        #Projection df

        projected_df =  pd.DataFrame()

        for index, row in testerd.iterrows():

            x = row['x']
            y = row['y']
            z = row['z']


            p = AzimuthalEquidistantProjection()
            r = p.project(Point(x,y,z))

            r = pd.Series(r)

            projected_df = projected_df.append(r,ignore_index=True)


        projected_df =  projected_df.rename(columns={0: 'X',1: 'Y'})


        ###map coodinate with valuies

        new_df = projected_df.join(extracted_df)
        new_df = new_df.drop([31]) # drop row because i contains no values
        #print(new_df)

        Theta_df = new_df.drop(['Alpha','Beta','X','Y'], axis=1)
        Alpha_df = new_df.drop(['Theta','Beta','X','Y'], axis=1)
        Beta_df = new_df.drop(['Theta','Alpha','X','Y'], axis=1)


        #map onto mesh

        xpoints = np.array(new_df[['X']].squeeze())
        ypoints = np.array(new_df[['Y']].squeeze())

        Thetavalues = np.array(Theta_df).squeeze()
        Alphavalues = np.array(Alpha_df).squeeze()
        Betavalues = np.array(Beta_df).squeeze()


        xx,yy = np.mgrid[-1.5:1.5:32j, -1.5:1.5:32j]

        Thetavalues = minmax_scale(Thetavalues,feature_range=(0.0, 1.0), axis=0)
        Alphavalues = minmax_scale(Alphavalues,feature_range=(0.0, 1.0), axis=0)
        Betavalues = minmax_scale(Betavalues,feature_range=(0.0, 1.0), axis=0)


        Thetagrid = griddata((xpoints, ypoints), Thetavalues, (xx, yy),method='cubic', fill_value = 0.0)
        Alphagrid = griddata((xpoints, ypoints), Alphavalues, (xx, yy),method='cubic', fill_value = 0.0)
        Betagrid = griddata((xpoints, ypoints), Betavalues, (xx, yy),method='cubic', fill_value = 0.0)


        ##RGB construction

        RGB = np.empty((32, 32, 3))

        RGB[:,:,0] = Thetagrid
        RGB[:,:,1] = Alphagrid
        RGB[:,:,2] = Betagrid



        RGB_dic[key] = RGB



    ##creating new dict with new keys

    lendict = len(RGB_dic)
    #print('lendict: ',lendict)

    lenlist=np.arange(0,lendict)

    #print(lenlist)

    final_dict = dict(zip(lenlist, list(RGB_dic.values())))


    return final_dict

print("Constructing Dataset...")

###Dataset construction

class EEGRGBDataset(Dataset):

    def __init__(self, file, transform=None):

        self.file = file
        self.transform = transform

    def __len__(self):
        return len(self.file)


    def __getitem__(self, idx):

        sample = self.file[idx]

        if self.transform:
            sample = self.transform(sample)

        return sample

class CNNFeatureExtractor(nn.Module):
    def __init__(self):
        super(CNNFeatureExtractor, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1)  # Flatten the dimensions for the feedforward layer
        return x

####Tensor transform


class ToTensor(object):
    def __call__(self, sample):

        sample = sample.transpose((2, 0, 1))
        sample = torch.tensor(sample, dtype = torch.float, device = device)

        return sample

### Function Call

# final_dict1 = trialfunction(Alc_train_extractor)
# final_dict2 = trialfunction(Con_train_extractor)
final_dict3 = trialfunction(Alc_train_classifier)
final_dict4 = trialfunction(Con_train_classifier)
final_dict5 = trialfunction(Alc_test)
final_dict6 = trialfunction(Con_test)

##

# eeg_dataset1 = EEGRGBDataset(final_dict1)
# eeg_dataset2 = EEGRGBDataset(final_dict2)

eeg_dataset3 = EEGRGBDataset(final_dict3)
eeg_dataset4 = EEGRGBDataset(final_dict4)

eeg_dataset5 = EEGRGBDataset(final_dict5)
eeg_dataset6 = EEGRGBDataset(final_dict6)

##

# transformed_dataset1 = EEGRGBDataset(eeg_dataset1, transform=transforms.Compose([ToTensor()]))
# transformed_dataset2 = EEGRGBDataset(eeg_dataset2, transform=transforms.Compose([ToTensor()]))

transformed_dataset3 = EEGRGBDataset(eeg_dataset3, transform=transforms.Compose([ToTensor()]))
transformed_dataset4 = EEGRGBDataset(eeg_dataset4, transform=transforms.Compose([ToTensor()]))

transformed_dataset5 = EEGRGBDataset(eeg_dataset5, transform=transforms.Compose([ToTensor()]))
transformed_dataset6 = EEGRGBDataset(eeg_dataset6, transform=transforms.Compose([ToTensor()]))

###Batch construction

bsize = 10
workers = 0


# loader1_Alc_train_extractor = DataLoader(transformed_dataset1, batch_size=bsize, num_workers=workers)
# loader2_Con_train_extractor = DataLoader(transformed_dataset2, batch_size=bsize, num_workers=workers)

loader3_Alc_train_classifier = DataLoader(transformed_dataset3, batch_size=bsize, num_workers=workers)
loader4_Con_train_classifier = DataLoader(transformed_dataset4, batch_size=bsize, num_workers=workers)

loader5_Alc_test = DataLoader(transformed_dataset5, batch_size=bsize, num_workers=workers)
loader6_Con_test = DataLoader(transformed_dataset6, batch_size=bsize, num_workers=workers)

distance = nn.MSELoss()

# Tensor construction
# for pytorch, the right format for image is [batch, channels, height, width]

#Training procedure

num_epochs = 1000

def feature_extractor(loader):

    with torch.no_grad():

        imagebatch = 0
        n = 0

        for batch in loader:
            n += 1

            inputs = batch.to(device)
            features = cnn_model(inputs)

            if n == 1:
                imagebatch = batch

            else:
                imagebatch = torch.cat([imagebatch, batch], dim=0, out=None)

        return imagebatch

### images for input

images_Alc_train_classifier = feature_extractor(loader3_Alc_train_classifier)
images_Con_train_classifier = feature_extractor(loader4_Con_train_classifier)

images_Alc_test_classifier = feature_extractor(loader5_Alc_test)
images_Con_test_classifier = feature_extractor(loader6_Con_test)


import numpy as np


##Labels

y_Alc_train_classifier = np.ones([images_Alc_train_classifier.shape[0]])
y_Con_train_classifier = np.zeros([images_Con_train_classifier.shape[0]])

y_Alc_test_classifier = np.ones([images_Alc_test_classifier.shape[0]])
y_Con_test_classifier= np.zeros([images_Con_test_classifier.shape[0]])

y_train_classifier = np.concatenate([y_Alc_train_classifier, y_Con_train_classifier], axis=0)
y_test_classifier = np.concatenate([y_Alc_test_classifier, y_Con_test_classifier], axis=0)

images_train_classifier = torch.cat([images_Alc_train_classifier, images_Con_train_classifier], dim=0)
images_test_classifier = torch.cat([images_Alc_test_classifier, images_Con_test_classifier], dim=0)




###into multiarray
images_train_classifier = images_train_classifier.cpu().numpy()

images_test_classifier = images_test_classifier.cpu().numpy()

###

from sklearn.utils import shuffle

S_images_train_classifier, S_y_train_classifier = shuffle(images_train_classifier, y_train_classifier, random_state=0)
S_images_test_classifier, S_y_test_classifier = shuffle(images_test_classifier, y_test_classifier, random_state=0)


###back to tensor
S_y_train_classifier = torch.tensor(S_y_train_classifier, dtype=torch.float, device = device)
S_y_test_classifier = torch.tensor(S_y_test_classifier, dtype=torch.float, device = device)

S_images_train_classifier = torch.tensor(S_images_train_classifier, dtype=torch.float, device = device)
S_images_test_classifier = torch.tensor(S_images_test_classifier, dtype=torch.float, device = device)




###flatten
Flat_S_images_train_classifier = torch.flatten(S_images_train_classifier,start_dim=1, end_dim=-1)
Flat_S_images_test_classifier = torch.flatten(S_images_test_classifier,start_dim=1, end_dim=-1)

class FeedforwardNeuralNetModel(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(FeedforwardNeuralNetModel, self).__init__()

        self.input_size = input_size
        self.hidden_size  = hidden_size
        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)
        self.relu = torch.nn.ReLU()
        self.fc2 = torch.nn.Linear(self.hidden_size, 1)
        self.sigmoid = torch.nn.Sigmoid()

    def forward(self, x):
        hidden = self.fc1(x)
        relu = self.relu(hidden)
        output = self.fc2(relu)
        output = self.sigmoid(output)
        return output

####
print()
print("Training classification models for imagesfor 100 epochs..")
print()
#Train FeedforwardNeuralNetModel

model = FeedforwardNeuralNetModel(3072,10)

distance =  nn.BCELoss()

FFoptimizer2 = torch.optim.SGD(model.parameters(), lr = 0.01)

#Training procedure

FFnum_epochs = 100

def FFtrainer(loaderx,labels, model, optimizer):

    for epoch in range(FFnum_epochs):

        optimizer.zero_grad()
        # Forward pass
        y_pred = model(loaderx)
        # Compute Loss
        loss = distance(y_pred.squeeze(), labels)

        # Backward pass
        loss.backward()
        optimizer.step()


        print('Epoch {}: train loss: {}'.format(epoch, loss.item()))

        # Print loss per epoch
        # if epoch == 0 or epoch == FFnum_epochs-1:
        #     print('Epoch {}: train loss: {}'.format(epoch, loss.item()))


### Determine test loss before training on test set


model.eval()
y_pred2 = model(Flat_S_images_test_classifier)
before_train = distance(y_pred2.squeeze(), S_y_test_classifier)
print('Test loss before training on images' , before_train.item())


#Training Call

model.train()
Model_images_train_classifier = FFtrainer(Flat_S_images_train_classifier,S_y_train_classifier,model,FFoptimizer2)


# Evaluation

model.eval()
y_pred = model(Flat_S_images_test_classifier)
after_train = distance(y_pred.squeeze(), S_y_test_classifier)
print('Test loss after Training on images' , after_train.item())

#Accuracy

output_pred = (y_pred>0.5).float()
correct = (output_pred.squeeze() == S_y_test_classifier).cpu().numpy().sum()
incorrect = (output_pred.squeeze() != S_y_test_classifier).cpu().numpy().sum()
total = correct + incorrect
accuracy = 100 * correct / total

print()
print("Summary of classifier accuracy:")
print()
print('Image accuracy:',accuracy,'%')
print()
print('In ',total,' test cases' )
print()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# 计算混淆矩阵
true_labels = S_y_test_classifier.cpu().numpy()
predicted_labels = output_pred.cpu().numpy()
cm = confusion_matrix(true_labels, predicted_labels)

# 绘制混淆矩阵
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# First, I'll read the contents of the uploaded file to understand its format.
file_path = '/content/drive/MyDrive/Conrad/eegdata/eegdata/plotting_1005.txt'

with open(file_path, 'r') as file:
    contents = file.readlines()

# Displaying the first few lines to understand the format of the data
contents[:5]

import seaborn as sns
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Parsing the data
sns.set(style="darkgrid")
points = {}
for line in contents:
    parts = line.strip().split('\t')
    if len(parts) == 4:
        label, x, y, z = parts
        points[label] = [float(x), float(y), float(z)]

# Extracting coordinates and labels for plotting
labels, x_coords, y_coords, z_coords = zip(*[(label, *coords) for label, coords in points.items()])

# Creating a 3D plot
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Plotting the points
ax.scatter(x_coords, y_coords, z_coords)

# Annotating the points with their labels
for i, label in enumerate(labels):
    ax.text(x_coords[i], y_coords[i], z_coords[i], label)

# Setting labels for axes
ax.set_xlabel('X Axis')
ax.set_ylabel('Y Axis')
ax.set_zlabel('Z Axis')

# Showing the plot
plt.show()

# Setting the Seaborn style for better aesthetics
sns.set(style="darkgrid")

# Creating a 3D plot without labels
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Plotting the points in color
sc = ax.scatter(x_coords, y_coords, z_coords, c=z_coords, cmap='viridis')

# Adding a color bar to indicate the values of the Z axis
plt.colorbar(sc)

# Setting labels for axes
ax.set_xlabel('X Axis')
ax.set_ylabel('Y Axis')
ax.set_zlabel('Z Axis')

# Showing the plot
plt.show()

from sklearn.decomposition import PCA

# Using PCA for dimensionality reduction to 2D
pca = PCA(n_components=2)
coords_2d_pca = pca.fit_transform(coords)

# Extracting the 2D coordinates from PCA
x_2d_pca, y_2d_pca = zip(*coords_2d_pca)

# Creating a 2D plot using Seaborn
plt.figure(figsize=(10, 8))
sns.scatterplot(x=x_2d_pca, y=y_2d_pca, palette='viridis')

# Setting labels for axes
plt.xlabel('PCA-1')
plt.ylabel('PCA-2')

# Showing the plot
plt.show()

# Extracting z-axis values for color mapping
z_values = [points[label][2] for label in labels]

# Creating a 2D plot with color representing the z-axis values
plt.figure(figsize=(10, 8))
scatter = plt.scatter(x=x_2d_pca, y=y_2d_pca, c=z_values, cmap='viridis')

# Adding a color bar to indicate the values of the Z axis
plt.colorbar(scatter, label='Height (Z-axis value)')

# Setting labels for axes
plt.xlabel('PCA-1')
plt.ylabel('PCA-2')

# Showing the plot
plt.show()

import numpy as np

def azimuthal_equidistant_projection(x, y, z):
    """
    Project 3D coordinates (x, y, z) onto a 2D plane using the Azimuthal Equidistant Projection.

    Assumes the center of the projection is at the north pole of the sphere.
    """
    # Convert Cartesian coordinates to spherical coordinates
    r = np.sqrt(x**2 + y**2 + z**2)
    theta = np.arctan2(y, x)  # azimuthal angle
    phi = np.arcsin(z / r)  # polar angle

    # Perform the azimuthal equidistant projection
    x_proj = r * np.cos(phi) * np.cos(theta)
    y_proj = r * np.cos(phi) * np.sin(theta)

    return x_proj, y_proj

# Applying the projection to each point
coords_2d_proj = [azimuthal_equidistant_projection(x, y, z) for x, y, z in coords]

# Extracting the projected 2D coordinates
x_2d_proj, y_2d_proj = zip(*coords_2d_proj)

# Creating a 2D plot with Seaborn
plt.figure(figsize=(10, 8))
sns.scatterplot(x=x_2d_proj, y=y_2d_proj, palette='viridis')

# Setting labels for axes
plt.xlabel('Projected X')
plt.ylabel('Projected Y')

# Showing the plot
plt.show()

# Creating a 3D plot and linking the points together to form a shape
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Plotting the points
ax.scatter(x_coords, y_coords, z_coords, c=z_coords, cmap='viridis')

# Linking the points together
for i in range(len(x_coords)-1):
    ax.plot([x_coords[i], x_coords[i+1]], [y_coords[i], y_coords[i+1]], [z_coords[i], z_coords[i+1]], color='blue')

# Setting labels for axes
ax.set_xlabel('X Axis')
ax.set_ylabel('Y Axis')
ax.set_zlabel('Z Axis')

# Showing the plot
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np

# 读取1005.txt文件中的3D坐标
coords = pd.read_csv(r'/content/drive/MyDrive/Conrad/eegdata/eegdata/plotting_1005.txt', sep='\t', header=None)
coords = coords.drop(coords.columns[4], axis=1)

# 提取X, Y, Z坐标
x = coords[1]
y = coords[2]
z = coords[3]
class AzimuthalEquidistantProjection:
    def __init__(self):
        self.t1 = np.pi / 2  # 竖直方向中心点
        self.l0 = 0  # 水平方向中心点
        self.cost1 = np.cos(self.t1)
        self.sint1 = np.sin(self.t1)

    def project(self, x, y, z):
        hxy = np.hypot(x, y)
        t = np.arctan2(z, hxy)
        l = np.arctan2(y, x)
        costcosll0 = np.cos(t) * np.cos(l - self.l0)
        sint = np.sin(t)
        c = np.arccos(self.sint1 * sint + self.cost1 * costcosll0)
        k = c / np.sin(c)
        x_2d = k * np.cos(t) * np.sin(l - self.l0)
        y_2d = k * (self.cost1 * sint - self.sint1 * costcosll0)
        return x_2d, y_2d

# 创建投影实例
proj = AzimuthalEquidistantProjection()

# 应用投影
x_2d, y_2d = np.array([proj.project(x_i, y_i, z_i) for x_i, y_i, z_i in zip(x, y, z)]).T

# 画出2D坐标图
plt.figure(figsize=(6, 6))
plt.scatter(x_2d, y_2d, c='b', marker='o')
plt.xlabel('X Axis')
plt.ylabel('Y Axis')
plt.title('2D Projected Electrode Positions')
plt.show()

from scipy.spatial import ConvexHull

# Extracting the original 3D coordinates as a numpy array
coords_array = np.array(list(zip(x_coords, y_coords, z_coords)))

# Creating a convex hull to determine the faces connecting the points
hull = ConvexHull(coords_array)

# Creating a 3D plot with faces formed by the points
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Plotting the convex hull
for simplex in hull.simplices:
    ax.plot(coords_array[simplex, 0], coords_array[simplex, 1], coords_array[simplex, 2], color='blue')

# Plotting the points
ax.scatter(coords_array[:, 0], coords_array[:, 1], coords_array[:, 2], c=coords_array[:, 2], cmap='viridis')

# Setting labels for axes
ax.set_xlabel('X Axis')
ax.set_ylabel('Y Axis')
ax.set_zlabel('Z Axis')

# Showing the plot
plt.show()

from mpl_toolkits.mplot3d.art3d import Poly3DCollection

# Creating a list of faces (triangles) for the convex hull
faces = [coords_array[simplex] for simplex in hull.simplices]

# Creating a 3D plot with filled faces
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Plotting the convex hull with filled faces
ax.add_collection3d(Poly3DCollection(faces, facecolors='blue', linewidths=1, alpha=0.3))

# Plotting the points
ax.scatter(coords_array[:, 0], coords_array[:, 1], coords_array[:, 2], c=coords_array[:, 2], cmap='viridis')

# Setting the limits for the axes based on the data
ax.set_xlim(np.min(coords_array[:,0]), np.max(coords_array[:,0]))
ax.set_ylim(np.min(coords_array[:,1]), np.max(coords_array[:,1]))
ax.set_zlim(np.min(coords_array[:,2]), np.max(coords_array[:,2]))

# Setting labels for axes
ax.set_xlabel('X Axis')
ax.set_ylabel('Y Axis')
ax.set_zlabel('Z Axis')

# Showing the plot
plt.show()

